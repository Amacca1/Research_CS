---
title: 'Fifth Day - 4/8'
description: 'Looking Into Chain of Thought'
pubDate: 'Aug 4 2025'
heroImage: '../../assets/blog-placeholder-2.jpg'
---

#### Looking into Chain of Thought Prompting

This section will primarily be looking at the 2022 Paper [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) and its rammifications into the development of AI into what it is today, and if (looking at the modern capabilities) how useful and effective it is in the modern landscape.

Chain of thought prompting is encouraging the LLM to provide a series of intermediate reasoning steps, to break down a complex problem into a series of small steps (a 'chain of thought') before getting to the final solution. To encourage the LLM to engage in Chain of thought (CoT) prompting it is provided a few demonstrations of chain of thought as examples. 

In 2022 this allowed even a weak LLM with poor reasoning skills to be on par/better with the best LLM at the time (Finetuned ChatGPT 3) with only 8 example prompts of CoT. 

This use of Chain of Thought combined 2 different ideas: the use of natural language to generate logic that can help with mathematical reasoning (either by training from scratch or finetuning an already trained model), and a relatively new concept - in context learning via prompting, instead of finetuning which was the main method to get a LLM to work upon a task well beyond a general level. As both ideas had limitations, the combination of the two fixed the shortfalls of the other (as finetuning/ training from scratch is incredibly costly and complicated to create the necessary dataset to train the LLM to a level of appropriate skill, and the in context prompting was poor at tasks that required reasoning abilitites and did not get better with the scale of the LLM). They did this by providing a prompt consisting of 3 things:
- Input
- Chain of Thought
- Output

Here is an example:

> Q: Roger has 5 tennis balls. He buys 2 more cans of
tennis balls. Each can has 3 tennis balls. How many
tennis balls does he have now?
A: Roger started with 5 balls. 2 cans of 3 tennis balls
each is 6 tennis balls. 5 + 6 = 11. The answer is 11.
Q: The cafeteria had 23 apples. If they used 20 to
make lunch and bought 6 more, how many apples
do they have?


This would provide the answer of:


> A: The cafeteria had 23 apples originally. They used
20 to make lunch. So they had 23 - 20 = 3. They
bought 6 more apples, so they have 3 + 6 = 9. The
answer is 9.


Previously, without Chain of Thought prompting, this would've provided the answer as 27. So even this small change in the style of prompting allows it to work out word equations when they were previously unable to.

##### Why is CoT useful?

It has many properties that are useful, beyond the fact that it allows a LLM to mimick how a human being would approach a multistep problem, via breaking it down into small decomposable chunks that can be solved before the next step until the overall problem is solved, but it also provides:

- An Window of insight into the behaviour of the model, allowing (if the answer is wrong) us to debug the path that a LLM took to the wrong answer
- Allows LLMs to solve essentially any task that humans can solve via language
- It can be quickly executed into any sufficiently large LLM with just a few examples of it being used.

![](/src/assets/resultsofCoT.png)

![](/src/assets/wordProblemsCoT.png)

Both images present shows that the addition of Chain of Thought Prompting allowed larger models to perform better (~100B parameters needed to show significant improvement), however it also at times worsened smaller models, as when they attempted to produce Chain of Thought reasoning, they produced illogical lines of thought, so produced more wrong answers on average.

The idea of Chain of Thought prompting revolutionised the capabilities of Language Models (particularly large ones), ushering in 'Prompt Engineering', which is an incredibly useful tool even today in 2025 for getting a LLM to work effectively and efficiently on any task presented to them. While not the only tool today due to the emergence of MCPs and tool/context engineering, as I wrote about on 29/7, prompt engineering is still a key principle for making AI work. 

However, as a result of this paper, we have moved on massively from this innovation. [The Decreasing Value of Chain of Thought in Prompting](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5285532) is a key paper that covers what I will be explaining and expanding on, with some research into if it truly does matter if modern day LLMs need the prompt engineering in order to:
1. Engage in Chain of Thought
2. Correctly answer math and commonsense reasoning questions